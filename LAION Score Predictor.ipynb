{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import LAION Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ICtSP\\AppData\\Local\\Temp\\ipykernel_27436\\1737881975.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  s = torch.load(path_to_model)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): VisionTransformer(\n",
       "    (conv1): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
       "    (patch_dropout): Identity()\n",
       "    (ln_pre): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0-23): 24 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): ModuleList(\n",
       "      (0-11): 12 x ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ls_1): Identity()\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (ls_2): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 768)\n",
       "  (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import open_clip\n",
    "from os.path import expanduser\n",
    "from urllib.request import urlretrieve\n",
    "import pandas as pd\n",
    "\n",
    "def get_aesthetic_model(clip_model=\"vit_l_14\"):\n",
    "    \"\"\"Load the aesthetic model\"\"\"\n",
    "    home = expanduser(\"~\")\n",
    "    cache_folder = os.path.join(home, \".cache\", \"emb_reader\")\n",
    "    path_to_model = os.path.join(cache_folder, f\"sa_0_4_{clip_model}_linear.pth\")\n",
    "    if not os.path.exists(path_to_model):\n",
    "        os.makedirs(cache_folder, exist_ok=True)\n",
    "        url_model = (\n",
    "            f\"https://github.com/LAION-AI/aesthetic-predictor/blob/main/sa_0_4_{clip_model}_linear.pth?raw=true\"\n",
    "        )\n",
    "        urlretrieve(url_model, path_to_model)\n",
    "    if clip_model == \"vit_l_14\":\n",
    "        m = nn.Linear(768, 1)\n",
    "    elif clip_model == \"vit_b_32\":\n",
    "        m = nn.Linear(512, 1)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported CLIP model type\")\n",
    "    s = torch.load(path_to_model)\n",
    "    m.load_state_dict(s)\n",
    "    m.eval()\n",
    "    return m\n",
    "\n",
    "\n",
    "# Load the aesthetic model\n",
    "amodel = get_aesthetic_model(clip_model=\"vit_l_14\")\n",
    "amodel.eval()\n",
    "\n",
    "# Load the CLIP model\n",
    "model, _, preprocess = open_clip.create_model_and_transforms('ViT-L-14', pretrained='openai')\n",
    "model.eval()\n",
    "\n",
    "def process_images_in_directory(directory_path):\n",
    "    results = []\n",
    "    # Iterate through all files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\")):  # Add or remove file extensions as needed\n",
    "            image_path = os.path.join(directory_path, filename)\n",
    "\n",
    "            # Open and preprocess the image  revise the code for my following instructions \n",
    "            image = preprocess(Image.open(image_path)).unsqueeze(0)\n",
    "\n",
    "            # Process the image\n",
    "            with torch.no_grad():\n",
    "                image_features = model.encode_image(image)\n",
    "                image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "                prediction = amodel(image_features)\n",
    "\n",
    "                score = prediction.item()\n",
    "                results.append({\"Filename\": filename, \"Aesthetic Score\": score})\n",
    "\n",
    "                print(f\"Aesthetic prediction for {filename}:\")\n",
    "                print(score)\n",
    "                print(\"-------------------------\")\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    # Calculate the mean score\n",
    "    mean_score = df[\"Aesthetic Score\"].mean()\n",
    "    print(f\"Mean Aesthetic Score: {mean_score}\")\n",
    "\n",
    "    # Add the mean score to the DataFrame\n",
    "    df = df._append({\"Filename\": \"Mean Score\", \"Aesthetic Score\": mean_score}, ignore_index=True)\n",
    "\n",
    "    # Save to Excel\n",
    "    foldername = os.path.basename(folder_path)\n",
    "    excel_path = os.path.join(directory_path, f\"{foldername}.xlsx\")\n",
    "    df.to_excel(excel_path, index=False)\n",
    "    print(f\"Results saved to {excel_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path='d:/Frank/Fall work/Prompt test'\n",
    "directory_path = 'd:/Frank/Fall work/Prompt test'\n",
    "process_images_in_directory(directory_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the excel in numerical order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted Excel file has been saved as d:/Frank/Fall work/generated_images/xl/only no greg/negative/1/sorted_1.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def natural_sort_key(s):\n",
    "    # Split the string into a list of strings and numbers\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split('(\\d+)', s)]\n",
    "\n",
    "# Loop through the range from 1 to 4\n",
    "for i in range(1,2):\n",
    "    # Use the loop variable to dynamically set the file paths\n",
    "    file_path = f'd:/Frank/Fall work/generated_images/xl/only no greg/negative/{i}/{i}.xlsx'\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    # Sort the DataFrame by the first column using the custom natural sort key\n",
    "    df_sorted = df.sort_values(by=df.columns[0], key=lambda col: col.map(natural_sort_key))\n",
    "\n",
    "    # Save the sorted DataFrame to a new Excel file\n",
    "    new_file_path = f'd:/Frank/Fall work/generated_images/xl/only no greg/negative/{i}/sorted_{i}.xlsx'\n",
    "    df_sorted.to_excel(new_file_path, index=False)\n",
    "\n",
    "    print(f'Sorted Excel file has been saved as {new_file_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ICtSP\\AppData\\Local\\Temp\\ipykernel_26416\\3673909037.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: np.nan if isinstance(x, float) and str(x).startswith('3.357') else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Excel file has been saved as d:/Frank/Fall work/generated_images/modified_LAION_Score.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = 'd:/Frank/Fall work/generated_images/LAION Score.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Replace values that start with \"3.357\" up to a certain precision with NaN\n",
    "df = df.applymap(lambda x: np.nan if isinstance(x, float) and str(x).startswith('3.357') else x)\n",
    "\n",
    "# Save the modified DataFrame to a new Excel file\n",
    "new_file_path = 'd:/Frank/Fall work/generated_images/modified_LAION_Score.xlsx'\n",
    "df.to_excel(new_file_path, index=False)\n",
    "\n",
    "print(f'Modified Excel file has been saved as {new_file_path}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nightshade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
